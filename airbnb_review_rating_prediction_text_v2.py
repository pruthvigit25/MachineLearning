# -*- coding: utf-8 -*-
"""airbnb_review_rating_prediction_text_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1daHOm2V1b4f2vZU-hKmhffCzD-kJa6zZ

# AirBnB Review Rating Prediction

Dataset: http://insideairbnb.com/get-the-data/

### Data Preparation

**Import the Required Packages**
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install emoji

import nltk
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sn
from collections import defaultdict, Counter
from typing import List, Tuple, Dict

from sklearn.model_selection import train_test_split

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

from sklearn.metrics import accuracy_score, precision_score, recall_score, balanced_accuracy_score
from sklearn.metrics import f1_score, mean_squared_error
from sklearn.metrics import classification_report
from sklearn.metrics import plot_confusion_matrix

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

import emoji

import warnings
warnings.filterwarnings('ignore')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

"""**Define Dataset Paths for Both Listing and Review Files** """

file_listing_path = "/content/drive/MyDrive/AirBnB/listings.csv"
file_review_path = "/content/drive/MyDrive/AirBnB/reviews.csv"

"""**Load Listing and Review Data Files into Dataframe** """

df_listing = pd.read_csv(file_listing_path)
df_review = pd.read_csv(file_review_path)

df_listing.shape

df_review.shape

"""*   **Convert Listing Id type (float => int => str)** 
*   **Show First 10 Records of Listing**
"""

df_listing = df_listing.astype({'id':'int'})
df_listing = df_listing.astype({'id':'str'})
df_listing.head(10)

"""**Pre-processing Listing Dataset**"""

df_listing["listing_id_str"] = 'C'
df_listing["listing_id_str"] = df_listing["listing_id_str"] + df_listing["id"] 
df_listing.drop(columns=['id'], inplace=True)
df_listing.head(10)

"""*   **Convert Listing Id type (float => int => str)** 
*   **Show First 10 Records of Listing**
"""

df_review.drop(columns=['id'], inplace=True)
df_review = df_review.astype({'listing_id':'int'})
df_review = df_review.astype({'listing_id':'str'})
df_review = df_review.astype({'comments':'str'})
df_review.head(10)

"""**Pre-processing Review Dataset**"""

df_review["listing_id_str"] = 'C'
df_review["listing_id_str"] = df_review["listing_id_str"] + df_review["listing_id"] 
df_review.drop(columns=['listing_id'], inplace=True)
df_review.head(10)

"""**Group All the Review Comments Specific to Each Listing as One Single Comment** """

df_review = df_review.groupby(['listing_id_str'], as_index = False).agg({'comments': ' '.join})

df_review_count = df_review.groupby(['listing_id_str'], as_index = False)['comments'].count()
df_review_count = df_review_count.join(df_listing.set_index(["listing_id_str"]), on=["listing_id_str"], how="inner")

df_review_count.sort_values(by=['review_scores_rating'], ascending=True)

"""We should rating distribution here."""

df_listing.shape

df_review.shape

"""**Join Review Data with Corresponding Listing**"""

df_airbnb = df_review.join(df_listing.set_index(["listing_id_str"]), on=["listing_id_str"], how="inner")
df_airbnb['comments'] = df_airbnb['comments'].apply(lambda x: emoji.demojize(x, delimiters=("", "")).replace("_", " "))
df_airbnb.head()

df_airbnb["review_scores_rating"] = np.round(df_airbnb["review_scores_rating"])
df_airbnb["review_scores_rating"] = df_airbnb["review_scores_rating"].fillna(0)
df_airbnb = df_airbnb.astype({'review_scores_rating':'int'})

df_airbnb["review_scores_accuracy"] = np.round(df_airbnb["review_scores_accuracy"])
df_airbnb["review_scores_accuracy"] = df_airbnb["review_scores_accuracy"].fillna(0)
df_airbnb = df_airbnb.astype({'review_scores_accuracy':'int'})

df_airbnb["review_scores_cleanliness"] = np.round(df_airbnb["review_scores_cleanliness"])
df_airbnb["review_scores_cleanliness"] = df_airbnb["review_scores_cleanliness"].fillna(0)
df_airbnb = df_airbnb.astype({'review_scores_cleanliness':'int'})

df_airbnb["review_scores_checkin"] = np.round(df_airbnb["review_scores_checkin"])
df_airbnb["review_scores_checkin"] = df_airbnb["review_scores_checkin"].fillna(0)
df_airbnb = df_airbnb.astype({'review_scores_checkin':'int'})

df_airbnb["review_scores_communication"] = np.round(df_airbnb["review_scores_communication"])
df_airbnb["review_scores_communication"] = df_airbnb["review_scores_communication"].fillna(0)
df_airbnb = df_airbnb.astype({'review_scores_communication':'int'})

df_airbnb["review_scores_location"] = np.round(df_airbnb["review_scores_location"])
df_airbnb["review_scores_location"] = df_airbnb["review_scores_location"].fillna(0)
df_airbnb = df_airbnb.astype({'review_scores_location':'int'})

df_airbnb["review_scores_value"] = np.round(df_airbnb["review_scores_value"])
df_airbnb["review_scores_value"] = df_airbnb["review_scores_value"].fillna(0)
df_airbnb = df_airbnb.astype({'review_scores_value':'int'})

df_airbnb["review_scores_rating"].value_counts(normalize=False)

"""**Split the Complete Dataset into Training (80%) and Test Dataset (20%)**"""

df_train, df_test = train_test_split(df_airbnb, test_size=0.20)

"""### Vectorization

We will try following settings for vectorization.

* Word representation: `CountVectorizer` vs. `TfidfVectorizer`
* N-grams: unigram & bigram
* Minimum document frequency: 5
* Convert to lowercase
* Use stop words
* Try binary counter
"""

def extract_features(df_train, df_test, class_column):
  vectorizer = CountVectorizer(analyzer='word', 
                               stop_words='english',
                               ngram_range=(1, 2),
                               lowercase=True,
                               min_df=5,
                               binary=False)
  X_train = vectorizer.fit_transform(df_train["comments"])
  X_test = vectorizer.transform(df_test["comments"])
  y_train = df_train[class_column].tolist()
  y_test = df_test[class_column].tolist()
  
  return X_train, X_test, y_train, y_test

X_train, X_test, y_train, y_test = extract_features(df_train, df_test, 'review_scores_rating')

def evaluate_model_Xy(model, X, y, y_pred=None, label="Training", model_name="model"):
  if y_pred is None:
    y_pred = model.predict(X)

  print(label + ' Set')
  print("Accuracy:", accuracy_score(y, y_pred))
  print("Balanced Accuracy:", balanced_accuracy_score(y, y_pred))
  print()

  print(classification_report(y, y_pred, digits=4))
  disp = plot_confusion_matrix(model, X, y, 
                               cmap=plt.cm.Blues, normalize='true')
  plt.savefig(model_name + "_" + label.lower() + ".eps")
  plt.show()
  print()

def evaluate_model(model, model_name="model", y_train_pred=None, y_test_pred=None):
  evaluate_model_Xy(model, X_train, y_train, label="Training", model_name=model_name)
  evaluate_model_Xy(model, X_test, y_test, label="Testing", model_name=model_name)

"""## Experiments and Results

We will use machine learning models and transformer-based models.

### Machine Learning

KNN, Logistic Regression, SVM, and Dummy Classifier will used in this section.

#### Logisitc Regression Classifier
"""

clf_lr = LogisticRegression(penalty='l2',
                            tol=1e-4,
                            C=5.0,
                            fit_intercept=True,
                            class_weight='balanced',
                            random_state=0,
                            solver='lbfgs',
                            max_iter=100,
                            multi_class='auto',
                            verbose=1,
                            n_jobs=-1)

clf_lr.fit(X_train, y_train)

evaluate_model(clf_lr, model_name="lr")

"""#### Linear Support Vector Machine (SVM)"""

clf_sgd = make_pipeline(StandardScaler(with_mean=False),
                        SGDClassifier(loss='hinge',
                                      penalty='l2',
                                      alpha=30,
                                      max_iter=1000, 
                                      tol=1e-3,
                                      shuffle=True,
                                      verbose=1,
                                      n_jobs=-1,
                                      random_state=0,
                                      learning_rate='optimal',
                                      early_stopping=True,
                                      class_weight='balanced'))

clf_sgd.fit(X_train, y_train)

evaluate_model(clf_sgd, model_name="sgd")

"""#### K Nearest Neighbour (KNN)"""

from sklearn.neighbors import KNeighborsClassifier

clf_knn = KNeighborsClassifier(n_neighbors=100)

clf_knn.fit(X_train, y_train)

evaluate_model(clf_knn, model_name="knn")

"""#### Dummy Classifier"""

from sklearn.dummy import DummyClassifier

clf_dummy = DummyClassifier(strategy="stratified")

clf_dummy.fit(X_train, y_train)

evaluate_model(clf_dummy, model_name="dummy")